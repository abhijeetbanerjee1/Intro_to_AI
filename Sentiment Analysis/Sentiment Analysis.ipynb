{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy,re\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authentication\n",
    "client = tweepy.Client(credentials.bearer_token, credentials.api_key, credentials.api_secret, credentials.acces_token, credentials.acces_token_secret)\n",
    "auth = tweepy.OAuth1UserHandler(credentials.api_key, credentials.api_secret, credentials.acces_token, credentials.acces_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input for term to be searched and how many tweets to search\n",
    "searchTerm = input(\"Enter Keyword/Tag to search about: \")\n",
    "NoOfTerms = int(input(\"Enter how many tweets to search: \"))\n",
    "\n",
    "tweets = []\n",
    "tweetText = []\n",
    "# searching for tweets\n",
    "tweets = client.search_recent_tweets(query = searchTerm+\" -is:retweet\", lang='en', max_result=NoOfTerms) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_list = [tweet.text for tweet in tweets]\n",
    "tweet_df = pd.DataFrame(tweet_list)\n",
    "tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(text):\n",
    "    return ' '.join(re.sub(\"(@[a-zA-Z0-9]+)|([^0-9A-Za-z])|(https://[\\w.]+/[\\w]+)\", \" \", text).split())\n",
    "\n",
    "tweet_df['cleaned_data'] = tweet_df[0].apply(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_numbers(list_text):\n",
    "    list_text_new = []\n",
    "    for i in list_text:\n",
    "        if not re.search('\\d', i):\n",
    "            list_text_new.append(i)\n",
    "    return ''.join(list_text_new)\n",
    "\n",
    "tweet_df['cleaned_data'] = tweet_df['cleaned_data'].apply(drop_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing all the words of the reviews column to lowercase letters\n",
    "def lower_case(text):\n",
    "    text_words = word_tokenize(text)\n",
    "    text_words_lower = [x.lower() for x in text_words]\n",
    "    return ' '.join(text_words_lower)\n",
    "\n",
    "tweet_df['cleaned_data'] = tweet_df['cleaned_data'].apply(lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatise(text):\n",
    "    text_tokens = word_tokenize(text)\n",
    "    text_lemm = [lemmatizer.lemmatize(word) for word in text_tokens]\n",
    "    return ' '.join(text_lemm)\n",
    "\n",
    "tweet_df['cleaned_data'] = tweet_df['cleaned_data'].apply(lemmatise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df['cleaned_data'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopword(text):\n",
    "    text_tokens = word_tokenize(text)\n",
    "    tokens = [word for word in text_tokens if not word in set(stopwords.words('english'))]\n",
    "    tokens_text = ' '.join(tokens)\n",
    "    return tokens_text\n",
    "\n",
    "tweet_df['cleaned_data'] = tweet_df['cleaned_data'].apply(remove_stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df['cleaned_data'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets calculate the Polarity of the Reviews\n",
    "def get_polarity(text):\n",
    "    textblob = TextBlob(str(text))\n",
    "    pol = textblob.sentiment.polarity\n",
    "    if(pol==0):\n",
    "        return \"Neutral\"\n",
    "    elif(pol>0 and pol<=0.3):\n",
    "        return \"Weakly Positive\"\n",
    "    elif(pol>0.3 and pol<=0.6):\n",
    "        return \"Positive\"\n",
    "    elif(pol>0.6 and pol<=1):\n",
    "        return \"Strongly Positive\"\n",
    "    elif(pol>-0.3 and pol<=0):\n",
    "        return \"Weakly Negative\"\n",
    "    elif(pol>-0.6 and pol<=-0.3):\n",
    "        return \"Negative\"\n",
    "    elif(pol>-1 and pol<=-0.6):\n",
    "        return \"Strongly Negative\"\n",
    "    \n",
    "tweet_df['polarity'] = tweet_df['cleaned_data'].apply(get_polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df['polarity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral = 0\n",
    "wpositive = 0\n",
    "spositive = 0\n",
    "positive = 0\n",
    "negative = 0\n",
    "wnegative = 0\n",
    "snegative = 0\n",
    "polarity = 0\n",
    "\n",
    "for i in range(0,70):\n",
    "    textblob = TextBlob(str(tweet_df['cleaned_data'][i]))\n",
    "    polarity+= textblob.sentiment.polarity\n",
    "    pol = textblob.sentiment.polarity\n",
    "    if (pol == 0):  # adding reaction of how people are reacting to find average later\n",
    "        neutral += 1\n",
    "    elif (pol > 0 and pol <= 0.3):\n",
    "        wpositive += 1\n",
    "    elif (pol > 0.3 and pol <= 0.6):\n",
    "        positive += 1\n",
    "    elif (pol > 0.6 and pol <= 1):\n",
    "        spositive += 1\n",
    "    elif (pol > -0.3 and pol <= 0):\n",
    "        wnegative += 1\n",
    "    elif (pol > -0.6 and pol <= -0.3):\n",
    "        negative += 1\n",
    "    elif (pol > -1 and pol <= -0.6):\n",
    "        snegative += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14114965986394554"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding average reaction\n",
    "polarity = polarity / NoOfTerms\n",
    "polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage(part, whole):\n",
    "    temp = 100 * float(part) / float(whole)\n",
    "    return format(temp, '.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    " # finding average of how people are reacting\n",
    "positive = percentage(positive, NoOfTerms)\n",
    "wpositive = percentage(wpositive, NoOfTerms)\n",
    "spositive = percentage(spositive, NoOfTerms)\n",
    "negative = percentage(negative, NoOfTerms)\n",
    "wnegative = percentage(wnegative, NoOfTerms)\n",
    "snegative = percentage(snegative, NoOfTerms)\n",
    "neutral = percentage(neutral, NoOfTerms)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # printing out data\n",
    "print(\"How people are reacting on \" + searchTerm + \" by analyzing \" + str(NoOfTerms) + \" tweets.\")\n",
    "print()\n",
    "print(\"-----------------------------------------------------------------------------------------\")\n",
    "print()\n",
    "print(\"General Report: \")\n",
    "\n",
    "if (polarity == 0):\n",
    "    print(\"Neutral\")\n",
    "elif (polarity > 0 and polarity <= 0.3):\n",
    "    print(\"Weakly Positive\")\n",
    "elif (polarity > 0.3 and polarity <= 0.6):\n",
    "    print(\"Positive\")\n",
    "elif (polarity > 0.6 and polarity <= 1):\n",
    "    print(\"Strongly Positive\")\n",
    "elif (polarity > -0.3 and polarity <= 0):\n",
    "    print(\"Weakly Negative\")\n",
    "elif (polarity > -0.6 and polarity <= -0.3):\n",
    "    print(\"Negative\")\n",
    "elif (polarity > -1 and polarity <= -0.6):\n",
    "    print(\"Strongly Negative\")\n",
    "\n",
    "print()\n",
    "print(\"------------------------------------------------------------------------------------------\")\n",
    "print()\n",
    "print(\"Detailed Report: \")\n",
    "print(str(positive) + \"% people thought it was positive\")\n",
    "print(str(wpositive) + \"% people thought it was weakly positive\")\n",
    "print(str(spositive) + \"% people thought it was strongly positive\")\n",
    "print(str(negative) + \"% people thought it was negative\")\n",
    "print(str(wnegative) + \"% people thought it was weakly negative\")\n",
    "print(str(snegative) + \"% people thought it was strongly negative\")\n",
    "print(str(neutral) + \"% people thought it was neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [positive, wpositive, spositive, neutral, negative, wnegative, snegative]\n",
    "colors = ['yellowgreen','lightgreen','darkgreen', 'gold', 'red','lightsalmon','darkred']\n",
    "labels = ['Positive [' + str(positive) + '%]', 'Weakly Positive [' + str(wpositive) + '%]',\n",
    "          'Strongly Positive [' + str(spositive) + '%]', 'Neutral [' + str(neutral) + '%]',\n",
    "          'Negative [' + str(negative) + '%]', 'Weakly Negative [' + str(wnegative) + '%]', \n",
    "          'Strongly Negative [' + str(snegative) + '%]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie(sizes, labels = labels, colors = colors)\n",
    "plt.legend(labels, loc=\"best\")\n",
    "plt.title('How people are reacting on ' + searchTerm + ' by analyzing ' + str(NoOfTerms) + ' Tweets.')\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
